{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%run base.ipynb\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tabulate\n",
    "\n",
    "# import signature policy and q-learning algorithm\n",
    "from sigqlearning_methods import train, test_multiple_episodes\n",
    "from sigqlearning_qfunctions import SigQFunction\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If results and plots from this notebook should be saved set `save=True` and select an identifiying prefix used for file names when saving results and plots, e.g. current date with a letter or number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_flag = False\n",
    "file_prefix = '20240903_A'\n",
    "\n",
    "if save_flag:\n",
    "    # check if files with selected prefix exist\n",
    "    from pathlib import Path\n",
    "    if len(list(Path('../results').glob(file_prefix + '*'))) + \\\n",
    "        len(list(Path('../figures').glob(file_prefix + '*'))) != 0:\n",
    "        file_prefix = input('Files with the chosen prefix already exist.\\nPlease enter new prefix.')\n",
    "    print('Results will be save with chosen prefix:', file_prefix)\n",
    "else:\n",
    "    print('Results will not be saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "steps = 200\n",
    "env = gym.make('MountainCar-v0', max_episode_steps=steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Q-function with different truncation orders\n",
    "\n",
    "We want to perform training runs for different signature truncation orders $N\\in\\mathbb{N}.$\n",
    "\n",
    "Specify the configuration of the Signature-Q-Function approximation and the training algorithm hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation_orders = [2, 3, 4, 5, 6, 7, 8]\n",
    "training_runs = 4\n",
    "\n",
    "# signature config, sig_depth will be added below\n",
    "sigq_params = dict(\n",
    "    in_channels = 2,\n",
    "    out_dimension = 3,\n",
    "    initial_basepoint = [-0.5, 1.],\n",
    "    initial_bias = -0.1 \n",
    ")\n",
    "\n",
    "# training config\n",
    "training_params = dict(\n",
    "    episodes = 4000,\n",
    "    discount=0.99,\n",
    "    learning_rate = 0.005,\n",
    "    learning_rate_decay = dict(mode=None), \n",
    "    epsilon = 0.3,\n",
    "    epsilon_decay = dict(mode='linear', end_value=0.05, epochs=2000),\n",
    "    decay_increment = 'success',\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each truncation order, we perform four training runs with all other hyperparameters held fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res_dict = {}\n",
    "\n",
    "for trunc_order in truncation_orders:\n",
    "    trunc_order_results = []\n",
    "\n",
    "    # run training algorithm loop\n",
    "    pbar = tqdm.trange(training_runs)\n",
    "    for run in range(training_runs):\n",
    "        pbar.set_description(\"Trunaction order: {}  |  Training runs\".format(trunc_order, run))\n",
    "        sigQfunction = SigQFunction(sig_depth=trunc_order, **sigq_params)\n",
    "        run_results = train(env, sigQfunction, **training_params) \n",
    "        trunc_order_results.append(run_results)\n",
    "    \n",
    "    train_res_dict[trunc_order] = trunc_order_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single run\n",
    "We plot the results for a specific run, set by ``run_id``. The results of interest are the reward obtained, the total loss occured, the car's end position, and the steps before reaching the goal or terminating, in each episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "trunc_order = 5\n",
    "run_id = 0\n",
    "\n",
    "print('Truncation order {} in training run {}: {} Successes'.format(\n",
    "    trunc_order, run_id, sum(np.array(train_res_dict[trunc_order][run_id][2])>=0.5)\n",
    "))\n",
    "utils.plot_results(train_res_dict[trunc_order], run=run_id, ma_window=100,\n",
    "                   title=\"Results for truncation {}, run {}\".format(trunc_order, run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaged over all runs for specific truncation order\n",
    "\n",
    "For a fixed truncation order, we average the results over all training runs and calculate the mean and standard deviation of\n",
    "- reward per episode\n",
    "- loss per episode\n",
    "- end position per episode\n",
    "- steps until termination per episode\n",
    "\n",
    "and plot the average results. Additionally we create one plot for each of the statistics and save under ``../figures``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_order = 5\n",
    "\n",
    "# select reward, loss, end position, steps for array\n",
    "results_array = np.array(\n",
    "    [train_res_dict[trunc_order][run][0:4] \n",
    "    for run in range(len(train_res_dict[trunc_order]))], \n",
    "    ndmin=3\n",
    ")\n",
    "training_results_means = results_array.mean(axis=0)\n",
    "training_results_stds = results_array.std(axis=0)\n",
    "\n",
    "utils.plot_mean_results(training_results_means, training_results_stds, \n",
    "                        title='Results averaged over training runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Q-values\n",
    "\n",
    "We check whether the Q-values at the beginning of the episode for a specified truncation order converge towards the same value as the overall reward obtained over the episode. This is an indication, that the algorithm learns the true optimal Q-values of the problem. Unfortunately this is not the case here.\n",
    "\n",
    "The first Q-values are plotted in two ways:\n",
    "- The actual first Q-values saved during training for each episode and calculated for the respective observation $o_0$ encountered in each episode.\n",
    "- The first Q-values for a fixed observation at $t=0$, for example $o_0 = (-0.5, 1.)$, calculated with the intermediate Q-functions saved during training each 10 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# choose truncation order, starting position and run_id\n",
    "trunc_order = 5\n",
    "start_position = -0.6\n",
    "run_id = -1\n",
    "\n",
    "sigqfunction = SigQFunction(sig_depth=trunc_order, **sigq_params)\n",
    "\n",
    "# plot with intermediate Q-function approximations\n",
    "utils.plot_first_Q_values(train_res_dict[trunc_order], run_id, intermediate_qfunctions=True,\n",
    "                          window=(1000,training_params['episodes']), sigq_container=sigqfunction,\n",
    "                          start_position=start_position, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First observation value\n",
    "Additionally we take a look at the value of the history at time $t=0$ for the start position $p_0 = -0.5$, which corresponds to the middle of the interval $[-0.6, -0.4]$ in which the car is placed randomly at the start of the episode. The value is calculated as the Q-values averaged over actions and is given by\n",
    "$$\n",
    "    V_0(\\hat{h}_0) = \\frac{1}{3}\\sum_{i=0}^2 Q(\\hat{h}_0, a_i),   \n",
    "$$\n",
    "It gives the value over an episode following a greedy policy based on the current approximate Q-function $Q$. If $V_0(\\hat{h}_0)$ converges towards the average reward over an episode, this indicates that the algorithm has converged to the true Q-values (at least for the Q-values at the start of the episode). Unfortunatly this is not the case here, since the algorithm over estimates Q-values.\n",
    "\n",
    "The plot displays the mean and standard deviation of $V_0(\\hat{h}_0)$ calculated over all performed training runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose truncation order\n",
    "trunc_order = 5\n",
    "\n",
    "# create array containing saved Q-values for all runs\n",
    "first_observations_array = np.array(\n",
    "    [train_res_dict[trunc_order][run][-3] for run in range(training_runs)]\n",
    ")\n",
    "value_means = first_observations_array.mean(axis=0)\n",
    "values_stds = first_observations_array.std(axis=0)\n",
    "\n",
    "utils.plot_first_obs_value(value_means, values_stds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Q-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the final Q-approximations for each truncation order and from each training run over a number of episodes and report statistics. \n",
    "\n",
    "Checkpoints of the `signatureQFunction` approximations during training was saved every 10 episodes and after the last training episode in each training run. The final learned approximation corresponds to the last checkpoint, given as `state_dict` of the `SigQFunction` class instance at the checkpoint time. Other approximation from training may be tested by selecting the appropriate checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose number of test episodes and Q-function checkpoint\n",
    "test_episodes = 500\n",
    "sigq_checkpoint_id = -1\n",
    "\n",
    "test_res_dict = {}\n",
    "\n",
    "for trunc_order in truncation_orders:\n",
    "    sigqfunction = SigQFunction(sig_depth=trunc_order, **sigq_params)\n",
    "    training_results = train_res_dict[trunc_order]\n",
    "    test_results = []\n",
    "    \n",
    "    pbar = tqdm.trange(training_runs)\n",
    "    for run in pbar:\n",
    "        pbar.set_description(\"Truncation order:  {}  |  Test runs\".format(trunc_order, run))\n",
    "        # load last Sig-Q approximation\n",
    "        sigqfunction.load_state_dict(training_results[run][-1][sigq_checkpoint_id])\n",
    "        sigqfunction.eval()\n",
    "        results = test_multiple_episodes(env, sigqfunction, \n",
    "                                         test_episodes, epsilon=0.0)\n",
    "        test_results.append(results)\n",
    "    \n",
    "    test_res_dict[trunc_order] = test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test statistics\n",
    "\n",
    "We display statistics as one table for each truncation order. This output format is not the best since we want to compare performance over truncation orders, however it will do to transfer it into a different format in the thesis document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_episodes = 500\n",
    "test_stats_dict = {}\n",
    "cols = ['Mean\\nreward', 'Std\\nreward', 'Successes', 'Mean\\nsteps', 'Std\\nsteps', 'Min\\nsteps', 'Max\\nsteps', 'Mean first\\nobs value']\n",
    "rows = ['Run {}'.format(i) for i in range(training_runs)]\n",
    "\n",
    "for trunc_order in truncation_orders:\n",
    "    trunc_order_stats = []\n",
    "    for test_run in test_res_dict[trunc_order]:\n",
    "        test_run_array = np.array(test_run[0:5])\n",
    "        test_run_stats = []\n",
    "        test_run_stats.append(test_run_array[0].mean()) # mean reward\n",
    "        test_run_stats.append(test_run_array[0].std()) # std reward\n",
    "        test_run_stats.append(100*test_run_array[1].sum()/test_episodes) # percentage successes\n",
    "        test_run_stats.append(test_run_array[2].mean()) # mean episode length\n",
    "        test_run_stats.append(test_run_array[2].std()) # std episode length\n",
    "        test_run_stats.append(int(test_run_array[2].min())) # min episode steps\n",
    "        test_run_stats.append(int(test_run_array[2].max())) # max episode steps\n",
    "        test_run_stats.append(test_run_array[4].mean()) # first observation value\n",
    "        \n",
    "        trunc_order_stats.append(test_run_stats)\n",
    "    \n",
    "    test_stats_dict[trunc_order] = trunc_order_stats\n",
    "    print(f'\\n\\nTest statistics for truncation order {trunc_order}:\\n')\n",
    "    print(tabulate.tabulate(trunc_order_stats, headers=cols, showindex=rows,floatfmt='.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain a more qualitative insight into the policy deriveed from the learned Q-function approximation, we may plot \n",
    "- the number of steps vs. start positions for a specific truncation order and run,\n",
    "- the observation trajectory for a specific truncation order, run and episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplots\n",
    "trunc_order = 5\n",
    "run_id = -1\n",
    "\n",
    "# start position vs. number of steps\n",
    "plt.figure(figsize=(5.5, 4.125))        \n",
    "plt.scatter(test_res_dict[trunc_order][run_id][3], \n",
    "            test_res_dict[trunc_order][run_id][2],\n",
    "            marker='x')\n",
    "plt.xlabel(\"Start position\", fontsize=11)\n",
    "plt.ylabel(\"Number of steps\", fontsize=11)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('../figures/{}_start_pos_vs_steps.png'.format(file_prefix))\n",
    "plt.show()\n",
    "\n",
    "# start position vs. reward\n",
    "plt.figure(figsize=(5.5, 4.125))        \n",
    "plt.scatter(test_res_dict[trunc_order][run_id][3], \n",
    "            test_res_dict[trunc_order][run_id][0],\n",
    "            marker='x')\n",
    "plt.xlabel(\"Start position\", fontsize=11)\n",
    "plt.ylabel(\"Reward\", fontsize=11)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('../figures/{}_start_pos_vs_reward.png'.format(file_prefix))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_flag:\n",
    "    # create file name and write results\n",
    "    file_path = '../results/' + file_prefix + '_truncation_order_results.pkl'\n",
    "    data_to_save = dict(truncation_orders=truncation_orders,\n",
    "                        sigq_params = sigq_params, \n",
    "                        training_params=training_params,\n",
    "                        train_res_dict=train_res_dict, \n",
    "                        test_res_dict=test_res_dict)\n",
    "    with open(file_path, 'wb') as f: \n",
    "        pickle.dump(data_to_save, f) # serialize the dict\n",
    "    print(\n",
    "        'Training, test results, parameter configuration saved under \\n \\\"{}\\\".'.format(\n",
    "            file_path\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results\n",
    "\n",
    "Instead of performing new training and testing runs, prior saved training and testing results, together with the parameter configuration used in training, may be loaded. Saved results can be found in `../results/` and are identified by a distinct `file_prefix`, e.g. the date the runs were performed, in the format `YYYYMMDD`, together with an upper case letter which enumerates the result saved on the same date. To load results select the respective `file_prefix` of the results to be loaded and set `execute_cell_flag = True`.\n",
    "\n",
    "The following objects are loaded:\n",
    "- `truncation_orders` - list containing the tested signature truncation orders\n",
    "- `sigq_params` - dict containing the signature-Q-function parameters\n",
    "- `training_params` - dict containing the training algorithm parameters\n",
    "- `train_res_dict` - dict, contains training run results for each truncation order\n",
    "- `test_res_dict` - dict, contains test run results for each truncation order\n",
    "â€“ `training_runs`- int, number of performed training runs per truncation order\n",
    "\n",
    "**Note:** To display results after loading them, the respective cells above this section need to be executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_cell_flag = False\n",
    "\n",
    "load_file_prefix = '20240903_A'\n",
    "file_path = '../results/' + load_file_prefix + '_truncation_order_results.pkl'\n",
    "\n",
    "if execute_cell_flag:\n",
    "    # set date and id of saved results to load\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_data_dict = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    truncation_orders = loaded_data_dict['truncation_orders']\n",
    "    sigq_params = loaded_data_dict['sigq_params']\n",
    "    training_params = loaded_data_dict['training_params']\n",
    "    train_res_dict = loaded_data_dict['train_res_dict']\n",
    "    test_res_dict = loaded_data_dict['test_res_dict']\n",
    "    training_runs = len(list(train_res_dict.values())[0])\n",
    "\n",
    "    print('Training, test results, parameter configuration loaded from: \\n \\\"{}\\\"\\n'.format(file_path))\n",
    "    print('Number of training runs: {}.\\nWith parameters:\\n'.format(training_runs))\n",
    "    pprint({key:loaded_data_dict[key] for key in loaded_data_dict if key not in ('train_res_dict', 'test_res_dict')})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
